비대면 : 
박철훈
조형순
이해성
백승민(지각)

scale
scale up  : 서버 한 대의  스펙을 올리는 것(CPU 2core -> 4core, RAM 1GB -> 4GB)
vs 
scale out : 동일한 서버를 여러 대 두는 것 
클라우드에서는 외부 트래픽에 대응하기 위하여 주로 "scale out" 을 사용한다. 

정리 ----------------------------------------------

컨테이너의 오케스트레이션 도구 : 일반적으로 클러스터 환경에서 필요한 자원(인스턴스, 컨테이너..) 을 적절히 배포, 회수 할 수 있는 도구
- swarm (도커에 기본적으로 내장되어 있음, 도커 프로젝트에 포함되어 있음)
   :  런타임 -> 도커

- kubernetes : 사실상 컨테이너 오케스트레이션의 표준이라고 할 수 있음
   :  런타임 -> 도커, rocket.. 

특징 :
- 오브젝트(pod, rs, deploy, service, configmap, secret..)를 사용하여 애플리케이션을 배포한다.
 - kubectl api-resources 를 통해 확인 가능
 - 오브젝트는 추상화된 집합 -> namespace (default, kube-system)
- 대부분의 리소스 오브젝트는 yaml 을 이용하여 배포한다.(yaml 파일 정의 -> 쿠버네티스에 적용)
- 마스터 노드 : master -> 클러스터 전체를 조율(control) 
               kube-apiserver : 관리자로부터 입력을 받아 처리하고, 결과를 화면에 출력시켜주는 도구(관리자와 쿠버네티스의 상호 통신 장소)
               etcd(key value store) : 클러스터의 데이터베이스를 백업하기 위한 장소
                                                              마스터는 노드, pod, 컨테이너 들의 상태 정보를 파악하기 위해 etcd 로 접속한다.
               control-manager : 실제 클러스터를 동작. 하나의 컨트롤러는 스케줄러를 참고하여 정확한 수의 포드를 실행한다. 포드에 문제가 발생하면 다른 컨트롤러가 이를 감지하고 대응한다.
               스케줄러 : 클러스터의 상태확인, 새로운 컨테이너가 필요하다면 어디에 배치할 것인지를 결정. 클러스터의 상태를 고려하여 어느 노드에 포드를 배치할 것인지를 결정한다. 

- (워커) 노드 : node     -> master 로 부터 작업을 부여 받아 이를 처리하는 기능을 갖는다
              kubelet : 컨트롤(mater)에서 노드에 작업 요청이 들어올 경우 kubelet 이 처리 
              runtime : kubetlet  으로 부터 작업 지시를 받고 실제 포드를 생성
               kube-proxy : 각 컴퓨팅 노드에서 k8s 네트워킹 서비스가 용이하도록 네트워크 환경제공
                                          트래픽 자체를 전달하여 클러스터 내부 또는 외부의 네트워크 통신 처리

 외부에서 서비스를 신청한 뒤 받고자한  일반 사용자는 __A___ 를 통해 __B__ 로 접속
  A : kube-proxy
 B : pod 


kubernets 의 설치 : kubeadm, kubespray 

PoD
컨테이너 애플리케이션의 기본 단위를 포드(Pod)
- 한개 이상의 컨테이너로 구성되어 있다.
- 도커 자체는 애플리케이션의 기본 단위 : 컨테이너
- 도커 스웜에서는 애플리케이션의 기본 단위 : 서비스(한개 이상의 컨테이너)
- 포드 내에 있는 컨테이너는 함께 움직인다. 분리되지 않는다. 
- 포드 내에 있는 컨테이너는 포드의 자원을 공유하여 사용하므로 분리하여 운영될 수 없다. 결국 하나의 포드 내에 있는 두개이상의 컨테이너는 서로 다른 노드에 배치 될 수 없다. 

apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  containers:
    - name: test-ctn
        image: centos:7
        ports:
        - containerPort: 80
           protocol: TCP  

레플리카 셋(Replica Set) : 일정 개수의 포드를 유지하는 컨트롤러
- 고정된 숫자 만큼의 포드를 항상 유지시킬 수 있다. 
- 만약 replica 가 3 으로 설정되어 있는 상태에서 한 개의 포드를 삭제한다면 rs 는 관리하는 label 을 항상확인하면서 부족한 포드를 채우게 된다. 

디플로이먼트(pod, rs 의 설정에 추가적으로 레플리카셋의 변경 사항을 저장하는 revision 을 남겨 향후에 롤백을 하 ㄹ수 있게 해 주고, 무중단으로 서비스를 롤링 업데이트 할 수 있다.

kubectl apply -f a.yaml --record  -> record 를 번호를 이용하여 롤백가능하다. 


[구성 예]
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-v1-deploy   <--- 관리를 위해 deployment 의 이름 작성
spec:
  replicas: 3                    <-- "color: black'이 붙은 포드를 3개 만들겠다
  selector:
    matchLabels:              <-- "color: black" 이 붙은 포드를 관리하겠다
     color: black
  template:
    metadata:
      name: my-nginx-v1   <--- 관리를 위한 pod 이름 
      labels:
        color: black                   <--- 각 포드에 라벨 "color: black" 을 부착!
    spec:
      containers:
      - name: my-nginx-ctn-v1
        image: beomtaek78/edustack:1.0
        ports:
        - containerPort: 80
           protocol: TCP



root@master:~/0524# cat testdeploy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: test-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      web: nginx
  template:
    metadata:
      name: test-pod
      labels:
        web: nginx
    spec:
      containers:
        - name: test-ctn
          image: nginx:1.0
          ports:
          - containerPort: 80
            protocol: TCP
root@master:~/0524#








 




root@master:~/0524# kubectl get pod,deploy
NAME                                READY   STATUS        RESTARTS   AGE
pod/test-deploy-6c7c6449fd-7dbkl    1/1     Running       0          14s
pod/test-deploy-6c7c6449fd-hgwpx    1/1     Running       0          14s
pod/test-deploy-6c7c6449fd-mnktd    1/1     Running       0          14s

NAME                          READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/test-deploy   3/3     3            3           14s
root@master:~/0524#
root@master:~/0524# kubectl rollout history deployment
deployment.apps/test-deploy
REVISION  CHANGE-CAUSE
1         kubectl apply --filename=testdeploy.yaml --record=true

root@master:~/0524#
root@master:~/0524# kubectl describe deploy test-deploy | grep nginx
Selector:               web=nginx
  Labels:  web=nginx
    Image:        nginx:1.10
root@master:~/0524#  # 동작중인 상태에서 이미지 업데이트 하기

첫번째 방법 : 파일 자체를 열고 이미지의 tag 를 바꾼다. -> apply
두번째 방법 : 
root@master:~/0524# kubectl set image deploy test-deploy test-ctn=nginx:1.12 --record
deployment.apps/test-deploy image updated
root@master:~/0524#
root@master:~/0524# kubectl describe deploy test-deploy | grep nginx
                        kubernetes.io/change-cause: kubectl set image deploy test-deploy test-ctn=nginx:1.12 --record=true
Selector:               web=nginx
  Labels:  web=nginx
    Image:        nginx:1.12
root@master:~/0524#

root@master:~/0524# kubectl get pod -o wide
NAME                            READY   STATUS        RESTARTS   AGE     IP                NODE    NOMINATED NODE   READINESS GATES
test-deploy-86bb49dd4-n5cg5     1/1     Running       0          48s     192.168.166.165   node1   <none>           <none>
test-deploy-86bb49dd4-thxqd     1/1     Running       0          42s     192.168.104.48    node2   <none>           <none>
test-deploy-86bb49dd4-x5xh2     1/1     Running       0          2m51s   192.168.104.45    node3   <none>           <none>
root@master:~/0524# 


네트워크를 위한 Service 오브젝트

pod를 배포하더라도 외부와의 연결은 불가능하다. 포드는 기본적으로 cluster-ip 를 통해 클러스터 내부에서 포드간 연결은 가능하다. 하지만 외부로의 연결을 위해서는 다음의 두가지 방법을 이용해야 한다. (cluster-ip 는 docker container run 할 때 -p 옵션 없는 것과 같다)

1. node-port : 각 물리서버(노드) 의 IP와 해당 포트를 cluster-ip 와 매핑하는 방법
2. lb : lb-node_port-cluster-ip 연결까지 한번에 할 수 있다. 단, 주로 lb 는 CSP(aws,gcp)와 같이 미리 LB 가 준비되어 있는 상태에서만 가능하다.  

root@master:~/0524# kubectl apply -f testnodeport.yaml
service/test-nodeport created
root@master:~/0524#
root@master:~/0524# cat testnodeport.yaml
apiVersion: v1
kind: Service
metadata:
  name: test-nodeport
spec:
  ports:
    - name: test-port
      port: 8080        #cluster-id
      targetPort: 80    #pod
      nodePort: 31000   #nodePort
  selector:
    web: nginx
  type: NodePort
root@master:~/0524# kubectl get svc
NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
kubernetes      ClusterIP   10.96.0.1       <none>        443/TCP          5d19h
test-nodeport   NodePort    10.105.81.207   <none>        8080:31000/TCP   11s
root@master:~/0524#

request : 상대방이 아무리 많은 자원을 사용하더라도 내가 사용할 수 있는 최소 request 만큼은 무조건 보장된다. 

overcommit : 상대방의 컨테이너가 많은 유휴(놀고있는) 자원을 가지고 있다면 overcommit 크기 만큼은 확장해서 사용할 수 있다. 물론 상대방이 자원사용률을 높이게 되면 다시 이를 줄여서 request 만큼 후퇴한다.  


---------- 실습 예제 -----------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: edustack
spec:
  selector:
    matchLabels:
      color: black
  replicas: 1
  template:
    metadata:
      labels:
        color: black
    spec:
      containers:
      - name: edustack-web
        image: beomtaek78/edustack:1.0
        ports:
        - containerPort: 80
        resources:
          limits:
            cpu: 500m
          requests:
            cpu: 200m

---

apiVersion: v1
kind: Service
metadata:
  name: edustack-np
spec:
  ports:
    - name: edustack-node-port
      port: 8080
      targetPort: 80
      nodePort: 30001
  selector:
    color: black
  type: NodePort


오토 스케일링을 위한 메트릭-서버 설치
wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

해당 파일 열고 136번째 줄에 아래와 같이 "- --kubelet-insecure-tls" 를 추가한다.
136         - --kubelet-insecure-tls

root@master:~/0524# kubectl top no --use-protocol-buffers
NAME     CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
master   287m         7%     2156Mi          56%
node1    98m          4%     1138Mi          61%
node2    101m         5%     1134Mi          60%
node3    101m         5%     1089Mi          58%
root@master:~/0524#


오토스케일러 작성하기 1
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: test-hpa
spec:
  maxReplicas: 10
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: edustack
  targetCPUUtilizationPercentage: 20

오토스케일러 작성하기 2
kubectl autoscale deploy edustack --cpu-percent=20 --min=1 --max=15


확인)
root@master:~/0524# kubectl top no --use-protocol-buffers ; kubectl get hpa
NAME     CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
master   286m         7%     2112Mi          55%
node1    99m          4%     1136Mi          61%
node2    106m         5%     1122Mi          60%
node3    102m         5%     1100Mi          59%
NAME       REFERENCE             TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
edustack   Deployment/edustack   0%/20%    1         15        1          4m14s
root@master:~/0524#



root@master:~/0524# kubectl top no --use-protocol-buffers ; kubectl get hpa
NAME     CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
master   489m         12%    2115Mi          55%
node1    1075m        53%    1137Mi          61%
node2    825m         41%    1122Mi          60%
node3    129m         6%     1098Mi          59%
NAME       REFERENCE             TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
edustack   Deployment/edustack   129%/20%   1         15        7          7m43s
root@master:~/0524#

[과제 수행]
- 현재까지 작성된 모든 오브젝트 중 pod, rs, deploy, service, hpa 등등을 모두 삭제하라.
- kubernetes 클러스터 환경에서 아래의 조건을 만족하는 환경을 구축하라
 
- 이미지는 centos 내에 httpd  를 설치하고 80번 포트를 오픈한다. 단, 페이지의 내용은 임의대로한다. 이미지는 1.0 버전과 2.0 버전 두개를 작성하고 index.html 파일의 내용만 달리한다. 두 이미지는 docker-hub에 미리 upload 해 둔다.
- deploy 를 이용하여 1.0 이미지의 pod 를 배포한다. 단, 초기는 1개만 배포한다.
- 이미지를 다운로드 할 때에는 Secret 을 적용하여 dockerhub 의 계정을 통해 이미지를 다운 받을 수 있어야 한다. (각 노드에서 docker login 하지 말것)
- Service 를 이용하여 외부에서 해당 포드로 접속이 가능해야 한다. 단, type 은 nodePort 를 사용하고 이를 외부에 구성된 HAProxy 를 통해 접근할 수 있어야 한다.
- auto-scale 을 구성하여 외부 접속량에 따라 자동으로 스케일이 up->down 될 수 있어야 한다.

- 외부에서 트래픽을 전송하고 이를 처리하는 결과를 그래프로 나타내라
   이를 위해 외부에서 트래픽은 ab(apache benchmark) 를 이용하고 그래프는 gnuplot 을 이용한다.
   그래프는 시간에 따라 외부에서 전송된 트래픽을 처리한 결과가 나타나야 한다.    

- 그래프의 결과를 토대로 deploy 내의 컨테이너에 대한 resource 를 적절히 조정하고 다시 외부에서 ab 를 이용하여 처리하는 시간을 줄이는 조정을 적용하라.
------------------------------------------------------------
추가) 프로메테우스+그라파나를 적용하여 그래프로 리소스에 대한 처리 내역등을 시각화 하라.
https://arisu1000.tistory.com/27857?category=787056
https://gruuuuu.github.io/cloud/monitoring-02/

 위의 과제가 완성된 사람은 결과를 jpg 파일로 작성한 뒤 이를 upload 하세요!!







--------------- 프로메테우스 설정 파일 -------------
아래의 내용을 pro.yaml 로 저장하고 실행 한 다음 포트포워딩을 하고, master 노드에서
http://localhost:9090/graph 로 접속하시면 됩니다.

root@master:~/0524# cat pro.yaml
------------- 이 아래에서 부터 복사하세요--------------------------------
# rbac.yaml

apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: monitoring
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: monitoring
  namespace: monitoring
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["get"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: monitoring
subjects:
  - kind: ServiceAccount
    name: monitoring
    namespace: monitoring
roleRef:
  kind: ClusterRole
  name: monitoring
  apiGroup: rbac.authorization.k8s.io
---
# prometheus-server-conf.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: prometheus-server-conf
  namespace: monitoring
data:
  prometheus.yaml: |-
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 15s
    rule_files:
      - "/etc/prometheus-rules/*.rules"
    alerting:
      alertmanagers:
      - scheme: http
        static_configs:
        - targets:
          - "alertmanager-http.monitoring.svc:9093"

    scrape_configs:
      - job_name: 'kubernetes-nodes'
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - source_labels: [__address__]
            regex: '(.*):10250'
            replacement: '${1}:10255'
            target_label: __address__

      - job_name: 'kubernetes-service-endpoints'
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_node_name]
            target_label: instance
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
            action: replace
            target_label: __scheme__
            regex: (https?)
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            target_label: __address__
            regex: (.+)(?::\d+);(\d+)
            replacement: $1:$2
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: kubernetes_name

      - job_name: 'kubernetes-services'
        metrics_path: /probe
        params:
          module: [http_2xx]
        kubernetes_sd_configs:
          - role: service
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
            action: keep
            regex: true
          - source_labels: [__address__]
            target_label: __param_target
          - target_label: __address__
            replacement: blackbox
          - source_labels: [__param_target]
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_service_name]
            target_label: kubernetes_name

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name
          - source_labels: [__meta_kubernetes_pod_container_port_number]
            action: keep
            regex: 9\d{3}

      - job_name: 'kubernetes-cadvisor'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

      - job_name: 'kube-state-metrics'
        static_configs:
          - targets: ['kube-state-metrics-http.monitoring:8080']

---
# prometheus-rules.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  labels:
    name: prometheus-rules
  namespace: monitoring
data:
  alert-rules.yaml: |-
    groups:
      - name: Node
        rules:
          - alert: Kubernetes PV Error
            expr: >
              kube_persistentvolume_status_phase{phase=~Failed|Pending, job=kube-state-metrics} > 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Kubernetes PersistentVolume error (pv: {{ $labels.persistentvolume }})
              description: Persistent volume is in {{ $value }}
              team: devops

          - alert: Kubernetes PVC Pending
            expr: >
              kube_persistentvolumeclaim_status_phase{job=kube-state-metrics, phase=Pending} == 1
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: Kubernetes PersistentVolumeClaim pending (instance: {{ $labels.instance }})
              description: PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending
              team: devops

          - alert: Kubernetes Node Ready
            expr: >
              kube_node_status_condition{job=kube-state-metrics, condition=Ready,status=true} == 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Kubernetes Node ready (node: {{ $labels.node }})
              description: Node {{ $labels.node }} has been unready for a long time
              team: devops

          - alert: Node Out Of Memory
            expr: >
              ((node_memory_MemTotal_bytes{job=kubernetes-service-endpoints} - node_memory_MemFree_bytes{job=kubernetes-service-endpoints}) / node_memory_MemTotal_bytes{job=kubernetes-service-endpoints}) * 100 > 90
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Node memory usage > 90% (instance: {{ $labels.instance }})
              description: {{ $value }}%
              team: devops

      - name: Pod
        rules:
          - alert: Container Cpu Usage
            expr: >
              sum(rate(container_cpu_usage_seconds_total{name!~.*prometheus.*, image!=, container!=POD, job=kubernetes-cadvisor}[5m])) by (container, namespace) / sum(container_spec_cpu_quota{name!~.*prometheus.*, image!=, container!=POD, job=kubernetes-cadvisor}/container_spec_cpu_period{name!~.*prometheus.*, image!=, container!=POD, job=kubernetes-cadvisor}) by (container, namespace) * 100 > 90
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Container CPU usage > 90% (namespace: {{ $labels.namespace }}, container: {{ $labels.container }})
              description: {{ $value }}%

          - alert: Container Memory Usage
            expr: >
              (avg (container_memory_working_set_bytes{container!=POD, container!=, job=kubernetes-cadvisor}) by (container , namespace)) / (avg (container_spec_memory_limit_bytes{container!=POD, container!=, job=kubernetes-cadvisor} > 0 ) by (container, namespace)) * 100 > 90
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Container Memory usage > 90% (namespace: {{ $labels.namespace }}, container: {{ $labels.container }})
              description: {{ $value }}%
              team: dev

          - alert: Kubernetes Statefulset Down
            expr: >
              (kube_statefulset_status_replicas_ready{job=kube-state-metrics} / kube_statefulset_status_replicas{job=kube-state-metrics}) != 1
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Kubernetes StatefulSet down (namespace: {{ $labels.namespace }}, statefulset: {{ $labels.statefulset }})
              description: A StatefulSet went down
              team: dev

          - alert: Kubernetes Pod Not Healthy
            expr: >
              min_over_time(sum by (namespace, pod) (kube_pod_status_phase{job=kube-state-metrics, phase=~Pending|Unknown|Failed})[5m:]) > 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: Kubernetes Pod not healthy (namespace: {{ $labels.namespace }})(pod: {{ $labels.pod }})
              description: Pod has been in a non-ready state for longer than a minute.
              team: dev

          - alert: Kubernetes Job Failed
            expr: >
              kube_job_status_failed{job=kube-state-metrics} > 0
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: Kubernetes Job failed (job: {{ $labels.job_name }})
              description: Job {{ $labels.namespace }} / {{ $labels.job_name }} failed to complete
              team: dev
---
# prometheus-pv.yaml

apiVersion: v1
kind: PersistentVolume
metadata:
  name: prometheus-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/mnt/data"
---
# prometheus-server-service.yaml

apiVersion: v1
kind: Service
metadata:
  name: prometheus-server-http
  namespace: monitoring
  labels:
    app: prometheus
  annotations:
    prometheus.io/scrape: "true"
spec:
  selector:
    app: prometheus
  type: NodePort
  ports:
    - port: 9090
      protocol: TCP
      name: prometheus
---
# prometheus-server-statefulset.yaml

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: prometheus-server
  namespace: monitoring
  labels:
    app: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  serviceName: prometheus-server-http
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: monitoring
      securityContext:
        runAsUser: 0
      containers:
        - name: prometheus
          image: prom/prometheus:v2.20.1
          args:
            - "--storage.tsdb.path=/prometheus"
            - "--storage.tsdb.retention.time=15d"
            - "--config.file=/etc/prometheus/prometheus.yaml"
            - "--web.enable-admin-api"
          ports:
            - name: prometheus
              containerPort: 9090
          resources:
            requests:
              cpu: 1
              memory: 1Gi
            limits:
              cpu: 1
              memory: 1Gi
          volumeMounts:
            - name: prometheus-storage
              mountPath: /prometheus
            - name: prometheus-server-conf
              mountPath: /etc/prometheus
            - name: prometheus-rules
              mountPath: /etc/prometheus-rules
      volumes:
        - name: prometheus-server-conf
          configMap:
            defaultMode: 420
            name: prometheus-server-conf
        - name: prometheus-rules
          configMap:
            name: prometheus-rules
  volumeClaimTemplates:
    - metadata:
        name: prometheus-storage
        namespace: monitoring
      spec:
        accessModes:
          - ReadWriteOnce
        storageClassName: manual
        resources:
          requests:
            storage: 20Gi
# then you type "kubectl apply -f pro.yaml", please type belows...
# kubectl port-forward svc/prometheus-server-http 9090:9090 -n monitoring
----------- 여기까지 복사해서 pro.yaml 파일을 만드세요--------------------






















